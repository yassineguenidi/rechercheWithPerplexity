# # import streamlit as st
# # import requests
# # import os
# # from dotenv import load_dotenv
# #
# # # Charger les cl√©s API
# # load_dotenv()
# # SERPER_API_KEY = os.getenv("SERPER_API_KEY")
# # HF_API_KEY = os.getenv("HF_API_KEY")
# #
# # # Fonction : recherche Google via Serper
# # def google_search(query):
# #     url = "https://google.serper.dev/search"
# #     headers = {"X-API-KEY": SERPER_API_KEY, "Content-Type": "application/json"}
# #     payload = {"q": query, "num": 10}  # limiter √† 10 r√©sultats
# #     response = requests.post(url, headers=headers, json=payload)
# #     if response.status_code == 200:
# #         return response.json().get("organic", [])
# #     else:
# #         return []
# #
# # # Fonction : r√©sum√© avec HuggingFace API
# # def generate_answer(context, question):
# #     prompt = f"Voici des extraits de recherche:\n{context}\n\nQuestion: {question}\nR√©ponds de mani√®re claire et concise."
# #     headers = {"Authorization": f"Bearer {HF_API_KEY}"}
# #     API_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
# #
# #     payload = {
# #         "inputs": prompt,
# #         "parameters": {"max_new_tokens": 500}
# #     }
# #
# #     response = requests.post(API_URL, headers=headers, json=payload)
# #     if response.status_code == 200:
# #         output = response.json()
# #         # Certains mod√®les renvoient la r√©ponse sous output[0]['generated_text']
# #         if isinstance(output, list) and 'generated_text' in output[0]:
# #             return output[0]['generated_text']
# #         else:
# #             return str(output)
# #     else:
# #         return f"Erreur API HuggingFace: {response.status_code} {response.text}"
# #
# # # Interface Streamlit
# # st.set_page_config(page_title="Mini Perplexity 2", layout="wide")
# # st.title("üîé Mini Perplexity 2 (Serper + HuggingFace)")
# #
# # query = st.text_input("Pose ta question :")
# #
# # if st.button("Rechercher") and query:
# #     with st.spinner("Recherche en cours..."):
# #         results = google_search(query)
# #
# #         if results:
# #             st.subheader("üìå Sources trouv√©es :")
# #             context = ""
# #             for r in results:
# #                 st.markdown(f"- [{r['title']}]({r['link']}) ‚Äî {r['snippet']}")
# #                 context += f"{r['title']}: {r['snippet']}\n"
# #
# #             # G√©n√©rer une r√©ponse
# #             answer = generate_answer(context, query)
# #             st.subheader("ü§ñ R√©ponse de l'IA :")
# #             st.write(answer)
# #         else:
# #             st.error("Aucun r√©sultat trouv√© ou quota atteint.")
#
#
# import streamlit as st
# import requests
# import os
# from dotenv import load_dotenv
#
# # Charger les cl√©s API
# load_dotenv()
# SERPER_API_KEY = os.getenv("SERPER_API_KEY")
# HF_API_KEY = os.getenv("HF_API_KEY")
#
#
# # Fonction : recherche Google via Serper
# def google_search(query):
#     url = "https://google.serper.dev/search"
#     headers = {"X-API-KEY": SERPER_API_KEY, "Content-Type": "application/json"}
#     payload = {"q": query, "num": 10}  # limiter √† 10 r√©sultats
#     response = requests.post(url, headers=headers, json=payload)
#     if response.status_code == 200:
#         return response.json().get("organic", [])
#     else:
#         st.error(f"Erreur Serper API: {response.status_code}")
#         return []
#
#
# # Fonction : r√©sum√© avec HuggingFace API
# def generate_answer(context, question):
#     prompt = f"Voici des extraits de recherche:\n{context}\n\nQuestion: {question}\nR√©ponds de mani√®re claire et concise."
#     headers = {"Authorization": f"Bearer {HF_API_KEY}"}
#     API_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
#
#     payload = {
#         "inputs": prompt,
#         "parameters": {"max_new_tokens": 500}
#     }
#
#     response = requests.post(API_URL, headers=headers, json=payload, timeout=60)
#
#     if response.status_code == 200:
#         output = response.json()
#         # V√©rifier si la r√©ponse contient du texte g√©n√©r√©
#         if isinstance(output, list) and len(output) > 0 and 'generated_text' in output[0]:
#             return output[0]['generated_text']
#         # Certains mod√®les renvoient directement du texte
#         elif isinstance(output, dict) and 'generated_text' in output:
#             return output['generated_text']
#         else:
#             return str(output)
#     else:
#         return f"Erreur HuggingFace API: {response.status_code} - {response.text}"
#
#
# # Interface Streamlit
# st.set_page_config(page_title="Mini Perplexity 2", layout="wide")
# st.title("üîé Mini Perplexity 2 (Serper + HuggingFace)")
#
# query = st.text_input("Pose ta question :")
#
# if st.button("Rechercher") and query:
#     with st.spinner("Recherche en cours..."):
#         # Rechercher sur Google via Serper
#         results = google_search(query)
#
#         if results:
#             st.subheader("üìå Sources trouv√©es :")
#             context = ""
#             for r in results:
#                 st.markdown(f"- [{r['title']}]({r['link']}) ‚Äî {r['snippet']}")
#                 context += f"{r['title']}: {r['snippet']}\n"
#
#             # G√©n√©rer la r√©ponse via HuggingFace
#             answer = generate_answer(context, query)
#             st.subheader("ü§ñ R√©ponse de l'IA :")
#             st.write(answer)
#         else:
#             st.error("Aucun r√©sultat trouv√© ou quota atteint.")


import streamlit as st
import requests
import os
from dotenv import load_dotenv

# ---------------------------
# Charger les cl√©s API
# ---------------------------
load_dotenv()
SERPER_API_KEY = os.getenv("SERPER_API_KEY")
HF_API_KEY = os.getenv("HF_API_KEY")

# ---------------------------
# Fonction : recherche Google via Serper
# ---------------------------
def google_search(query, num_results=10):
    url = "https://google.serper.dev/search"
    headers = {"X-API-KEY": SERPER_API_KEY, "Content-Type": "application/json"}
    payload = {"q": query, "num": num_results}
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        if response.status_code == 200:
            return response.json().get("organic", [])
        else:
            st.error(f"Erreur Serper API: {response.status_code} - {response.text}")
            return []
    except Exception as e:
        st.error(f"Erreur lors de la recherche Serper: {str(e)}")
        return []

# ---------------------------
# Fonction : r√©sum√© avec HuggingFace API
# ---------------------------
# def generate_answer(context, question):
#     if not HF_API_KEY:
#         return "Erreur : HuggingFace API Key introuvable. V√©rifiez votre fichier .env."
#
#     prompt = f"Voici des extraits de recherche:\n{context}\n\nQuestion: {question}\nR√©ponds de mani√®re claire et concise."
#     headers = {"Authorization": f"Bearer {HF_API_KEY}"}
#     API_URL = "https://api-inference.huggingface.co/models/deepset/roberta-base-squad2"
#     payload = {"inputs": prompt, "parameters": {"max_new_tokens": 500}}
#
#     try:
#         response = requests.post(API_URL, headers=headers, json=payload, timeout=60)
#         if response.status_code == 200:
#             output = response.json()
#             # Certains mod√®les renvoient la r√©ponse dans output[0]['generated_text']
#             if isinstance(output, list) and len(output) > 0 and 'generated_text' in output[0]:
#                 return output[0]['generated_text']
#             elif isinstance(output, dict) and 'generated_text' in output:
#                 return output['generated_text']
#             else:
#                 return str(output)
#         elif response.status_code == 401:
#             return "Erreur : Cl√© HuggingFace invalide ou manquante (401)."
#         elif response.status_code == 403:
#             return "Erreur : Acc√®s interdit √† l'API HuggingFace (403)."
#         else:
#             return f"Erreur API HuggingFace: {response.status_code} - {response.text}"
#     except Exception as e:
#         return f"Erreur lors de l'appel HuggingFace API: {str(e)}"


# ---------------------------
# Fonction : r√©sum√© avec HuggingFace API
# ---------------------------
def generate_answer(context, question):
    if not HF_API_KEY:
        return "Erreur : HuggingFace API Key introuvable. V√©rifiez votre fichier .env."

    # Format correct pour l'API de question-r√©ponse
    payload = {
        "inputs": {
            "question": question,
            "context": context
        },
        "parameters": {
            "max_answer_len": 500,
            "max_seq_len": 512
        }
    }

    headers = {"Authorization": f"Bearer {HF_API_KEY}"}
    API_URL = "https://api-inference.huggingface.co/models/deepset/roberta-base-squad2"

    try:
        response = requests.post(API_URL, headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            output = response.json()
            # Le mod√®le roberta-base-squad2 renvoie la r√©ponse dans 'answer'
            if isinstance(output, dict) and 'answer' in output:
                return output['answer']
            else:
                return f"Format de r√©ponse inattendu: {str(output)}"
        elif response.status_code == 401:
            return "Erreur : Cl√© HuggingFace invalide ou manquante (401)."
        elif response.status_code == 403:
            return "Erreur : Acc√®s interdit √† l'API HuggingFace (403)."
        else:
            return f"Erreur API HuggingFace: {response.status_code} - {response.text}"
    except Exception as e:
        return f"Erreur lors de l'appel HuggingFace API: {str(e)}"

# ---------------------------
# Interface Streamlit
# ---------------------------
st.set_page_config(page_title="Mini Perplexity 2", layout="wide")
st.title("üîé Mini Perplexity 2 (Serper + HuggingFace)")

query = st.text_input("Pose ta question :")

if st.button("Rechercher") and query:
    with st.spinner("Recherche en cours..."):
        # 1Ô∏è‚É£ Recherche via Serper
        results = google_search(query)
        if results:
            st.subheader("üìå Sources trouv√©es :")
            context = ""
            for r in results:
                st.markdown(f"- [{r['title']}]({r['link']}) ‚Äî {r['snippet']}")
                context += f"{r['title']}: {r['snippet']}\n"

            # 2Ô∏è‚É£ G√©n√©rer la r√©ponse via HuggingFace
            answer = generate_answer(context, query)
            st.subheader("ü§ñ R√©ponse de l'IA :")
            st.write(answer)
        else:
            st.error("Aucun r√©sultat trouv√© ou quota Serper atteint.")
